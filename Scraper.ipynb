{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "\n",
        "# URLs of the pages to scrape\n",
        "urls = [\n",
        "    \"https://alphaai.company/top-personal-injury-law-firms-in-ontario/\",\n",
        "    \"https://alphaai.company/top-personal-injury-law-firms-in-alberta/\",\n",
        "    \"https://alphaai.company/top-personal-injury-law-firms-in-quebec/\",\n",
        "    \"https://alphaai.company/top-personal-injury-law-firms-in-british-columbia/\",\n",
        "    \"https://alphaai.company/top-personal-injury-law-firms-in-newfoundland-and-labrador/\"\n",
        "]\n",
        "\n",
        "# Function to extract province from URL\n",
        "def extract_province(url):\n",
        "    province_mappings = {\n",
        "        \"ontario\": \"Ontario\",\n",
        "        \"alberta\": \"Alberta\",\n",
        "        \"quebec\": \"Quebec\",\n",
        "        \"british-columbia\": \"British Columbia\",\n",
        "        \"newfoundland-and-labrador\": \"Newfoundland and Labrador\"\n",
        "    }\n",
        "\n",
        "    for key, value in province_mappings.items():\n",
        "        if key in url.lower():\n",
        "            return value\n",
        "\n",
        "    return \"Unknown\"\n",
        "\n",
        "# Function to scrape a single page\n",
        "def scrape_page(url):\n",
        "    try:\n",
        "        print(f\"Attempting to scrape: {url}\")\n",
        "\n",
        "        # Add a delay to be respectful to the server\n",
        "        time.sleep(2)\n",
        "\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, headers=headers, timeout=30)\n",
        "            response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Failed to fetch {url}: {e}\")\n",
        "            return None\n",
        "\n",
        "        print(f\"Successfully fetched page content, length: {len(response.text)}\")\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Get province from URL\n",
        "        province = extract_province(url)\n",
        "\n",
        "        # Extract page title (h1)\n",
        "        title_element = soup.find('div', class_='law-firm-rankings-heading')\n",
        "        title = title_element.find('h1').text.strip() if title_element and title_element.find('h1') else \"Unknown Title\"\n",
        "\n",
        "        # Extract description (paragraph text)\n",
        "        description_element = soup.find('div', class_='low-firm-rankings-description')\n",
        "        description = \"\"\n",
        "        if description_element and description_element.find_all('p'):\n",
        "            for p in description_element.find_all('p'):\n",
        "                if p.text.strip():\n",
        "                    description += p.text.strip() + \" \"\n",
        "        description = description.strip()\n",
        "\n",
        "        # Extract firm data\n",
        "        firms = []\n",
        "        firm_sections = soup.find_all('div', class_='ranked-firm-section')\n",
        "\n",
        "        print(f\"Found {len(firm_sections)} firm sections\")\n",
        "\n",
        "        for idx, section in enumerate(firm_sections, 1):\n",
        "            try:\n",
        "                firm_data = {\"rank\": idx, \"province\": province}\n",
        "\n",
        "                # Find the info container\n",
        "                info_container = section.find('div', class_='law-firm-rankings-info')\n",
        "                if not info_container:\n",
        "                    continue\n",
        "\n",
        "                # Extract firm name and website\n",
        "                name_div = section.find('div', class_='rankings-info-name')\n",
        "                if name_div and name_div.find('a'):\n",
        "                    firm_data['name'] = name_div.find('a').text.strip()\n",
        "                    firm_data['website'] = name_div.find('a').get('href')\n",
        "                else:\n",
        "                    # Try alternative structure\n",
        "                    links = section.find_all('a')\n",
        "                    for link in links:\n",
        "                        if not link.get('href').startswith('http'):\n",
        "                            continue\n",
        "                        if \"linkedin\" not in link.get('href', ''):\n",
        "                            firm_data['website'] = link.get('href')\n",
        "                            if not firm_data.get('name') and link.text.strip():\n",
        "                                firm_data['name'] = link.text.strip()\n",
        "\n",
        "                # Try to extract monthly visits\n",
        "                visit_span = section.find('span', class_='rankings-info-monthly-visits')\n",
        "                if visit_span:\n",
        "                    visit_text = visit_span.text.strip()\n",
        "                    # Extract just the visit number (like \"25K-50K monthly visits\")\n",
        "                    visit_match = re.search(r'(\\d+[KM]?-\\d+[KM]?|\\d+[KM]?\\+?) monthly visits', visit_text)\n",
        "                    if visit_match:\n",
        "                        firm_data['monthly_visits'] = visit_match.group(1)\n",
        "                    else:\n",
        "                        firm_data['monthly_visits'] = visit_text\n",
        "\n",
        "                # Try to extract LinkedIn URL\n",
        "                linkedin_link = section.find('a', href=lambda href: href and 'linkedin.com' in href.lower())\n",
        "                if linkedin_link:\n",
        "                    firm_data['linkedin'] = linkedin_link.get('href')\n",
        "\n",
        "                # If we have at least a name or website, add the firm\n",
        "                if firm_data.get('name') or firm_data.get('website'):\n",
        "                    firms.append(firm_data)\n",
        "                    print(f\"Extracted firm: {firm_data.get('name', 'Unknown')}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting firm data: {e}\")\n",
        "                continue\n",
        "\n",
        "        return {\n",
        "            'province': province,\n",
        "            'title': title,\n",
        "            'description': description,\n",
        "            'firms': firms,\n",
        "            'url': url\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to save data to files\n",
        "def save_data(all_data):\n",
        "    # Create a backup of existing files if they exist\n",
        "    import os\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    for filename in ['law_firms_data.json', 'law_firms_data.csv']:\n",
        "        if os.path.exists(filename):\n",
        "            backup_name = f\"{filename.split('.')[0]}_{timestamp}.{filename.split('.')[1]}\"\n",
        "            os.rename(filename, backup_name)\n",
        "            print(f\"Created backup of existing file: {backup_name}\")\n",
        "\n",
        "    # Save the data to a JSON file\n",
        "    with open('law_firms_data.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    # Create a flattened DataFrame for easier processing\n",
        "    firms_list = []\n",
        "    for province_data in all_data:\n",
        "        if province_data and 'firms' in province_data:\n",
        "            for firm in province_data['firms']:\n",
        "                firms_list.append(firm)\n",
        "\n",
        "    if firms_list:\n",
        "        df = pd.DataFrame(firms_list)\n",
        "        df.to_csv('law_firms_data.csv', index=False)\n",
        "        print(f\"Data saved to CSV with {len(df)} records\")\n",
        "    else:\n",
        "        print(\"No firm data to save to CSV\")\n",
        "\n",
        "# Main function to scrape all pages\n",
        "def scrape_all_pages():\n",
        "    all_data = []\n",
        "\n",
        "    for url in urls:\n",
        "        print(f\"\\n===== Scraping: {url} =====\")\n",
        "        page_data = scrape_page(url)\n",
        "        if page_data and page_data.get('firms'):\n",
        "            all_data.append(page_data)\n",
        "            print(f\"Successfully scraped {len(page_data['firms'])} firms for {page_data['province']}\")\n",
        "        else:\n",
        "            print(f\"Failed to scrape data from {url}\")\n",
        "\n",
        "    save_data(all_data)\n",
        "    return all_data\n",
        "\n",
        "# Alternative: If the URLs aren't accessible, use local HTML files\n",
        "def process_local_html(file_path, province_name):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            html_content = f.read()\n",
        "\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "        # Extract title\n",
        "        title_element = soup.find('div', class_='law-firm-rankings-heading')\n",
        "        title = title_element.find('h1').text.strip() if title_element and title_element.find('h1') else f\"Top Personal Injury Law Firms in {province_name}\"\n",
        "\n",
        "        # Extract description\n",
        "        description_element = soup.find('div', class_='low-firm-rankings-description')\n",
        "        description = \"\"\n",
        "        if description_element:\n",
        "            description = description_element.text.strip()\n",
        "\n",
        "        # Extract firms\n",
        "        firms = []\n",
        "        firm_sections = soup.find_all('div', class_='ranked-firm-section')\n",
        "\n",
        "        for idx, section in enumerate(firm_sections, 1):\n",
        "            try:\n",
        "                firm_data = {\"rank\": idx, \"province\": province_name}\n",
        "\n",
        "                # Find firm name and website\n",
        "                name_element = section.find('div', class_='rankings-info-name')\n",
        "                if name_element and name_element.find('a'):\n",
        "                    firm_data['name'] = name_element.find('a').text.strip()\n",
        "                    firm_data['website'] = name_element.find('a').get('href')\n",
        "\n",
        "                # Find monthly visits\n",
        "                visits_span = section.find('span', class_='rankings-info-monthly-visits')\n",
        "                if visits_span:\n",
        "                    firm_data['monthly_visits'] = visits_span.text.strip()\n",
        "\n",
        "                # Find LinkedIn\n",
        "                linkedin = section.find('a', href=lambda href: href and 'linkedin.com' in href)\n",
        "                if linkedin:\n",
        "                    firm_data['linkedin'] = linkedin.get('href')\n",
        "\n",
        "                if firm_data.get('name') or firm_data.get('website'):\n",
        "                    firms.append(firm_data)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing firm: {e}\")\n",
        "                continue\n",
        "\n",
        "        return {\n",
        "            'province': province_name,\n",
        "            'title': title,\n",
        "            'description': description,\n",
        "            'firms': firms\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing local HTML: {e}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Try scraping from URLs first\n",
        "    data = scrape_all_pages()\n",
        "\n",
        "    if not data:\n",
        "        print(\"\\nURL scraping failed. Processing local HTML files if available...\")\n",
        "        # Define mappings for local HTML files\n",
        "        local_files = {\n",
        "            \"ontario.html\": \"Ontario\",\n",
        "            \"alberta.html\": \"Alberta\",\n",
        "            \"quebec.html\": \"Quebec\",\n",
        "            \"british_columbia.html\": \"British Columbia\",\n",
        "            \"newfoundland.html\": \"Newfoundland and Labrador\"\n",
        "        }\n",
        "\n",
        "        local_data = []\n",
        "        for file_name, province in local_files.items():\n",
        "            if os.path.exists(file_name):\n",
        "                print(f\"Processing local file: {file_name}\")\n",
        "                province_data = process_local_html(file_name, province)\n",
        "                if province_data:\n",
        "                    local_data.append(province_data)\n",
        "\n",
        "        if local_data:\n",
        "            save_data(local_data)\n",
        "            print(f\"Processed {len(local_data)} local HTML files\")\n",
        "        else:\n",
        "            print(\"No data could be scraped from URLs or local files\")\n",
        "    else:\n",
        "        print(f\"Successfully scraped data from {len(data)} pages\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHSZvosTU_le",
        "outputId": "d469e5b2-0388-4b53-c8ab-a6921c84559c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Scraping: https://alphaai.company/top-personal-injury-law-firms-in-ontario/ =====\n",
            "Attempting to scrape: https://alphaai.company/top-personal-injury-law-firms-in-ontario/\n",
            "Successfully fetched page content, length: 231845\n",
            "Found 15 firm sections\n",
            "Extracted firm: Siskinds Law Firm\n",
            "Extracted firm: McLeish Orlando LLP\n",
            "Extracted firm: Gluckstein LLP\n",
            "Extracted firm: SG Injury Law\n",
            "Extracted firm: Diamond and Diamond Lawyers\n",
            "Extracted firm: Harrison Pensa\n",
            "Extracted firm: Howie, Sacks & Henry LLP\n",
            "Extracted firm: Bergeron Clifford Injury Lawyers\n",
            "Extracted firm: Boland Romaine LLP\n",
            "Extracted firm: Neinstein Personal Injury Lawyers\n",
            "Extracted firm: Samfiru Tumarkin LLP\n",
            "Extracted firm: Iacobelli Law Firm\n",
            "Extracted firm: David Hollingsworth\n",
            "Extracted firm: Lalande Personal Injury Lawyers\n",
            "Extracted firm: Roger R. Foisy & Associates\n",
            "Successfully scraped 15 firms for Ontario\n",
            "\n",
            "===== Scraping: https://alphaai.company/top-personal-injury-law-firms-in-alberta/ =====\n",
            "Attempting to scrape: https://alphaai.company/top-personal-injury-law-firms-in-alberta/\n",
            "Successfully fetched page content, length: 230991\n",
            "Found 15 firm sections\n",
            "Extracted firm: McLeod Law LLP\n",
            "Extracted firm: Edwards Injury Law\n",
            "Extracted firm: Litco Law\n",
            "Extracted firm: James H. Brown & Associates\n",
            "Extracted firm: Chadi & Company\n",
            "Extracted firm: Braithwaite Boyle\n",
            "Extracted firm: The Accident Lawyers - Personal Injury Lawyers Calgary\n",
            "Extracted firm: Kahane Law Office\n",
            "Extracted firm: Stringam LLP\n",
            "Extracted firm: Rodin Law Firm\n",
            "Extracted firm: Kazlaw Personal Injury Lawyers\n",
            "Extracted firm: Grover Law Firm\n",
            "Extracted firm: Assiff Law Office\n",
            "Extracted firm: McLeish Orlando LLP\n",
            "Extracted firm: Warnett Hallen LLP\n",
            "Successfully scraped 15 firms for Alberta\n",
            "\n",
            "===== Scraping: https://alphaai.company/top-personal-injury-law-firms-in-quebec/ =====\n",
            "Attempting to scrape: https://alphaai.company/top-personal-injury-law-firms-in-quebec/\n",
            "Successfully fetched page content, length: 231881\n",
            "Found 15 firm sections\n",
            "Extracted firm: MedLÃ©gal\n",
            "Extracted firm: Kalman Samuels Attorneys\n",
            "Extracted firm: Annette Lefebvre Avocats\n",
            "Extracted firm: McLeish Orlando LLP\n",
            "Extracted firm: Diamond and Diamond Lawyers\n",
            "Extracted firm: Gluckstein LLP\n",
            "Extracted firm: Desroches Mongeon Avocats\n",
            "Extracted firm: Preszler Injury Lawyers\n",
            "Extracted firm: SG Injury Law\n",
            "Extracted firm: Boland Romaine LLP\n",
            "Extracted firm: Warnett Hallen LLP\n",
            "Extracted firm: David Hollingsworth\n",
            "Extracted firm: Neinstein Personal Injury Lawyers\n",
            "Extracted firm: Samfiru Tumarkin LLP\n",
            "Extracted firm: Bergeron Clifford Injury Lawyers\n",
            "Successfully scraped 15 firms for Quebec\n",
            "\n",
            "===== Scraping: https://alphaai.company/top-personal-injury-law-firms-in-british-columbia/ =====\n",
            "Attempting to scrape: https://alphaai.company/top-personal-injury-law-firms-in-british-columbia/\n",
            "Successfully fetched page content, length: 230556\n",
            "Found 15 firm sections\n",
            "Extracted firm: Kazlaw Personal Injury Lawyers\n",
            "Extracted firm: Bungay Law Office\n",
            "Extracted firm: Preszler Injury Lawyers\n",
            "Extracted firm: Baker Newby\n",
            "Extracted firm: Diamond and Diamond Lawyers\n",
            "Extracted firm: Tim Louis & Company Law\n",
            "Extracted firm: Lemer & Company\n",
            "Extracted firm: James H. Brown & Associates\n",
            "Extracted firm: Samfiru Tumarkin LLP\n",
            "Extracted firm: Slater Vecchio LLP\n",
            "Extracted firm: Stephens & Holman\n",
            "Extracted firm: Neinstein Personal Injury Lawyers\n",
            "Extracted firm: Gosal & Company | Workers' Compensation Lawyers (WorkSafeBC/WCB)\n",
            "Extracted firm: FH&P Lawyers\n",
            "Extracted firm: MacIsaac Gow LLP\n",
            "Successfully scraped 15 firms for British Columbia\n",
            "\n",
            "===== Scraping: https://alphaai.company/top-personal-injury-law-firms-in-newfoundland-and-labrador/ =====\n",
            "Attempting to scrape: https://alphaai.company/top-personal-injury-law-firms-in-newfoundland-and-labrador/\n",
            "Successfully fetched page content, length: 232174\n",
            "Found 15 firm sections\n",
            "Extracted firm: MacGillivray Injury and Insurance Law\n",
            "Extracted firm: Russell Accident Law\n",
            "Extracted firm: Rogers Rogers Moyse\n",
            "Extracted firm: Diamond and Diamond Lawyers\n",
            "Extracted firm: McLeish Orlando LLP\n",
            "Extracted firm: Gittens, de Beer & Associates\n",
            "Extracted firm: O'Dea Earle Injury Lawyers\n",
            "Extracted firm: Roebothan McKay Marshall\n",
            "Extracted firm: Gluckstein LLP\n",
            "Extracted firm: NOVA Injury Law\n",
            "Extracted firm: Warnett Hallen LLP\n",
            "Extracted firm: Jasmine Daya & Co.\n",
            "Extracted firm: Ryder-Burbidge Hurley Foster (RBHF) Professional Corporation\n",
            "Extracted firm: Aaron Waxman and Associates\n",
            "Extracted firm: Auger Hollingsworth\n",
            "Successfully scraped 15 firms for Newfoundland and Labrador\n",
            "Data saved to CSV with 75 records\n",
            "Successfully scraped data from 5 pages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HzPj2D4rDRJH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}